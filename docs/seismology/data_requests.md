# Data Requests

## Mass Downloaders

### Stream2segment (GFZ)

    https://github.com/rizac/stream2segment/blob/master/README.md

Zaccarelli, R., Bindi, D., Strollo, A., Quinteros, J., & Cotton, F. (2019). Stream2segment:
An Open‐Source Tool for Downloading, Processing, and Visualizing Massive Event‐Based Seismic
Waveform Datasets. Seismological Research Letters, 90(5), 2028. http://doi.org/10.1785/0220180314.


### obspyDMT (Oxford)

    https://github.com/kasra-hosseini/obspyDMT

Hosseini, K., & Sigloch, K. (2017). ObspyDMT: a Python toolbox for retrieving and processing
large seismological data sets. Solid Earth, 8(5), 1047–1070. http://doi.org/10.5194/se-8-1047-2017


### ObsPy mass_downloader module

    https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.mass_downloader.html

    obspy.clients.fdsn - FDSN Web service client for ObsPy

    https://docs.obspy.org/packages/obspy.clients.fdsn.html

Good for complex or larger queries:

    obspy.clients.fdsn.mass_downloader (for multiple data centers)

## FDSNWS


Using web services: FDSNWS & IRISWS

### Station data (FDSNWS)

    http://service.iris.edu/fdsnws/station/1/query?...

Type http_request_string in a web browser or use `wget` or `curl` from command line

    $ wget -O output_file "http_request_string"

(quotation marks are important to avoid that the shell interprets special characters)

Use HTTP POST

All of the parameters that can be submitted with the GET method are allowed in POST
with the following exceptions: startbefore, endbefore, startafter, endafter

    $ wget --post-file=post_request_file -O output_file http://service.iris.edu/fdsnws/station/1/query

Example of post_request_file:

    level=channel
    format=text
    TA A25A -- BH? 2010-03-25T00:00:00 2010-04-01T00:00:00
    IU ANMO * BH? 2010-03-25T00:00:00 2010-04-01T00:00:00
    IU ANMO 10 HHZ 2010-03-25T00:00:00 2010-04-01T00:00:00
    II KURK 00 BH? 2010-03-25T00:00:00 2010-04-01T00:00:00

In general:

    parameter=<value>
    parameter=<value>
    parameter=<value>
    <network> <station> <location> <channel> <starttime> <endtime>
    <network> <station> <location> <channel> <starttime> <endtime>
    ...


### Event data (FDSNWS)

    http://service.iris.edu/fdsnws/event/1/query?...

This service will not be offered long term, so it is better to go directly to ISC/NEIC

### Waveform data (FDSNWS)

    http://service.iris.edu/fdsnws/dataselect/1/query?...

Same options:

- type URL in web browser (small requests)
- wget/curl (automated or scripted requests)
- HTTP POST (automated or scripted requests)

    quality=<D|R|Q|M|B>
    minimumlength=<seconds>
    longestonly=<true|false>
    <Network> <Station> <Location> <Channel> <StartTime> <EndTime>
    ...

### Waveform data (IRISWS)

    http://service.iris.edu/irisws/timeseries/1/query?...

accepts HTTP POST?

Signal processing options:

+ high, low and band-pass filter
+ remove mean value
+ scaling by constant value
+ deconvolution of instrument response (with frequency limits and unit conversion)
+ differentiation and integration
+ decimation to lower sample rates

- good for complex or large queries


### Other IRIS web services


- `fedcatalog`: A service for federating requests for channel metadata across multiple data centers

- `syngine`: A service for synthetic seismograms

- `timeseriesplot`: A charting webservice offering timeseries graphic display in single-line or helicorder styles

- `rotation`: rotate waveform data into alternate coordinate system

- `sacpz`: instrument response information (per channel)

- `resp`: channel response information

- `evalresp`: instrument response information evaluated from IRIS metadata

- `virtualnetwork`: list of stations in a virtual network

- `traveltime`: travel times and ray parameters for seismic phases using a 1-D spherical earth model

- `flinnengdahl`: a Flinn-Engdahl region code or name for a latitude, longitude pair

- `distaz`: distance, azimuth and back-azimuth between two locations

- `metadatachange`: changes made to SEED metadata

## Other tools

### JWEED

JWEED and other IRIS software use web services

### Fetch scripts

FetchData-2016.089.txt
FetchEvent-2014.340.txt
FetchMetadata-2014.316.txt
FetchSyn-2016.007.txt

Advantages:

- access to other data centers (see -F option)
- can read from BREQ_FAST file

## CWBQuery

Backup vdl account and cwb from edge1.ictja.csic.es

1. Backup data files

```console
ndatapath=2
datapath=/data2/cwb/			-> edge2.icjta.csic.es:/data9/cwb2/cwb/*.ms *.idx
datapath1=/data1/cwb/			-> edge2.ictja.csic.es:/data8/cwb1/cwb/*.ms *.idx
```

2. Backup vdl home directory

```console
$ cd /home
$ tar cvzf ~antonio/backups/vd_edge1.tgz vdl
```

(includes `.bash* files`)

Older backups are:

```
edge1.tar
edge1dot.tar (hidden files and directories: .*)
edge2.tar
```

3. Save crontab file

```console
$ crontab -e

# DO NOT EDIT THIS FILE - edit the master and reinstall.
# (/tmp/crontab.31532 installed on Mon Aug  3 16:07:26 2009)
# (Cron version -- $Id: crontab.c,v 2.13 1994/01/17 03:20:37 vixie Exp $)
* * * * * bash scripts/chkInvToSEED 200 >>LOG/InvToSEED.log1 2>&1
* * * * * bash scripts/chkJarProcessGC TcpHoldings 200 >>LOG/TcpHoldings.log1 2>&1
* * * * * bash scripts/chkJarProcessGC QueryServer 100 "" "" -allowrestricted >> LOG/QueryServer.log1 2>&1
* * * * * bash scripts/chkJarProcessGC EdgeMom 400 >>LOG/EdgeMom.log1 2>&1
```

4. Save `/etc/security/limits.conf`

```console
$ cat /etc/security/limits.conf
# /etc/security/limits.conf
#
#Each line describes a limit for a user in the form:
#
#<domain>        <type>  <item>  <value>
#
#Where:
#<domain> can be:
#        - an user name
#        - a group name, with @group syntax
#        - the wildcard *, for default entry
#        - the wildcard %, can be also used with %group syntax,
#                 for maxlogin limit
#        - NOTE: group and wildcard limits are not applied to root.
#          To apply a limit to the root user, <domain> must be
#          the literal username root.
#
#<type> can have the two values:
#        - "soft" for enforcing the soft limits
#        - "hard" for enforcing hard limits
#
#<item> can be one of the following:
#        - core - limits the core file size (KB)
#        - data - max data size (KB)
#        - fsize - maximum filesize (KB)
#        - memlock - max locked-in-memory address space (KB)
#        - nofile - max number of open files
#        - rss - max resident set size (KB)
#        - stack - max stack size (KB)
#        - cpu - max CPU time (MIN)
#        - nproc - max number of processes
#        - as - address space limit (KB)
#        - maxlogins - max number of logins for this user
#        - maxsyslogins - max number of logins on the system
#        - priority - the priority to run user process with
#        - locks - max number of file locks the user can hold
#        - sigpending - max number of pending signals
#        - msgqueue - max memory used by POSIX message queues (bytes)
#        - nice - max nice priority allowed to raise to values: [-20, 19]
#        - rtprio - max realtime priority
#        - chroot - change root to directory (Debian-specific)
#
#<domain>      <type>  <item>         <value>
#

#*               soft    core            0
#root            hard    core            100000
#*               hard    rss             10000
#@student        hard    nproc           20
#@faculty        soft    nproc           20
#@faculty        hard    nproc           50
#ftp             hard    nproc           0
#ftp             -       chroot          /ftp
#@student        -       maxlogins       4
vdl soft nofile 4096
vdl hard nofile 4096

# End of file
```

5. Backup `/etc/sudoers`

```console
$ sudo visudo

# /etc/sudoers
#
# This file MUST be edited with the 'visudo' command as root.
#
# See the man page for details on how to write a sudoers file.
#

Defaults        env_reset

# Host alias specification

# User alias specification

User_Alias APOLLOUSERS = antonio,iber,jdiaz,mario,estevet,sofia
User_Alias INPUTUSERS = antonio,iber,jdiaz,mario,estevet,sofia

# Cmnd alias specification

Cmnd_Alias APOLLOCOMMANDS = /usr/bin/java, /bin/kill
Cmnd_Alias INPUTCOMMANDS = /bin/cp, /bin/mv, /bin/rm, /bin/mkdir, /bin/rmdir, /bin/chmod

APOLLOUSERS ALL=(root) NOPASSWD: APOLLOCOMMANDS
INPUTUSERS ALL=(input) NOPASSWD: INPUTCOMMANDS

# User privilege specification
root    ALL=(ALL) ALL
vdl     ALL=(ALL) ALL

# Uncomment to allow members of group sudo to not need a password
# (Note that later entries override this, so you might need to move
# it further down)
# %sudo ALL=NOPASSWD: ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL
```

6. Backup mysql databases

```console
$ mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 4432
Server version: 5.1.72-0ubuntu0.10.04.1 (Ubuntu)

Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.

.
.
.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| DZ                 |
| DZDATA             |
| DZSTATS            |
| DZTMP              |
| FB                 |
| FBDATA             |
| FBSTATS            |
| FBTMP              |
| FR                 |
| FRDATA             |
| FRSTATS            |
| FRTMP              |
| IB                 |
| IBDATA             |
| IBSTATS            |
| IBTMP              |
| IP                 |
| IPDATA             |
| IPSTATS            |
| IPTMP              |
| PQLXMETA           |
| TAPAS              |
| TAPASDATA          |
| TAPASSTATS         |
| TAPASTMP           |
| TEST               |
| TESTDATA           |
| TESTSTATS          |
| TESTTMP            |
| X7                 |
| X7DATA             |
| X7STATS            |
| X7TMP              |
| anss               |
| edge               |
| inv                |
| mysql              |
| status             |
+--------------------+
39 rows in set (0.00 sec)

mysql> quit
Bye
```

```console
$ mysqldump -u root -pSunMysqlRoot --add-drop-table -c edge > BACKUP_SQL/edge.sql
$ mysqldump -u root -pSunMysqlRoot --add-drop-table -c anss > BACKUP_SQL/anss.sql
$ mysqldump -u root -pSunMysqlRoot --add-drop-table -c inv > BACKUP_SQL/inv.sql 
$ mysqldump -u root -pSunMysqlRoot --add-drop-table -c status > BACKUP_SQL/status.sql
```




